import os
import pandas as pd
import numpy as np
from catboost import CatBoostRegressor
from sklearn.model_selection import train_test_split
import shap
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import streamlit as st
from zhipuai import ZhipuAI  # æ›¿æ¢ä¸ºæ–°çš„å¯¼å…¥æ–¹å¼
import json  # æ–°å¢ï¼šå¯¼å…¥ json æ¨¡å—

# ç¡®ä¿è¾“å‡ºæ–‡ä»¶å¤¹å­˜åœ¨
output_folder = 'd:/newml/data_splits'
os.makedirs(output_folder, exist_ok=True)

# åŠ è½½æ•°æ®
file_path = 'd:/newml/output_expanded_additives_pubchem_encoded.csv'
df = pd.read_csv(file_path)

# ç¡®ä¿ JV_default_PCE åˆ—ä¸ºæ•°å€¼ç±»å‹
df['JV_default_PCE'] = pd.to_numeric(df['JV_default_PCE'], errors='coerce')

# æ¸…ç†åˆ—åï¼Œç¡®ä¿åªåŒ…å« ASCII å­—ç¬¦
df.columns = [str(col).encode('ascii', errors='ignore').decode() for col in df.columns]

# æ¸…ç†å­—ç¬¦ä¸²ç±»å‹çš„åˆ—ï¼Œç¡®ä¿åªåŒ…å« ASCII å­—ç¬¦
for col in df.select_dtypes(include=['object']).columns:
    df[col] = df[col].apply(lambda x: str(x).encode('ascii', errors='ignore').decode())

# å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
X = df.drop(columns=['JV_default_PCE'])
y = df['JV_default_PCE']
X = X.fillna(-1)  # ç¡®ä¿æ²¡æœ‰ç¼ºå¤±å€¼

# æŒ‰ç…§ 7:2:1 çš„æ¯”ä¾‹åˆ’åˆ†æ•°æ®é›†ï¼Œéšæœºç§å­ä¿æŒä¸å˜
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=833)  # 70% è®­ç»ƒé›†
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.33, random_state=43)  # 20% éªŒè¯é›†ï¼Œ10% æµ‹è¯•é›†

# ä¿å­˜åˆ’åˆ†åçš„æ•°æ®é›†åˆ°ä¸åŒçš„CSVæ–‡ä»¶
X_train.to_csv(os.path.join(output_folder, 'X_train.csv'), index=False)
y_train.to_csv(os.path.join(output_folder, 'y_train.csv'), index=False)
X_val.to_csv(os.path.join(output_folder, 'X_val.csv'), index=False)
y_val.to_csv(os.path.join(output_folder, 'y_val.csv'), index=False)
X_test.to_csv(os.path.join(output_folder, 'X_test.csv'), index=False)
y_test.to_csv(os.path.join(output_folder, 'y_test.csv'), index=False)

# åŠ è½½ä¿å­˜çš„æ¨¡å‹
model_path = 'd:/newml/best_model.cbm'
model = CatBoostRegressor()
model.load_model(model_path)

# Streamlit åº”ç”¨
st.title("Perovskite Additives Performance Prediction")

# æ–°å¢ï¼šåœ¨å…¨å±€ä½œç”¨åŸŸä¸­åˆå§‹åŒ– prediction å˜é‡
prediction = None

# æ–°å¢ï¼šä½¿ç”¨å®¹å™¨ä¼˜åŒ–å¸ƒå±€
with st.container():
    col1, col2 = st.columns([3, 2])
    with col1:
        # åŸºå‡†æ ·æœ¬é€‰æ‹©ä¼˜åŒ–
        baseline_df = df[df['JV_default_PCE'] > 20].head(10)
        selected_baseline = st.selectbox("é€‰æ‹©åŸºå‡†æ ·æœ¬", baseline_df.index, 
                                       help="é€‰æ‹©æ€§èƒ½è¶…è¿‡20çš„åŸºå‡†æ ·æœ¬ä½œä¸ºå‚è€ƒ")
        
        # è·å–é€‰å®šçš„åŸºå‡†æ ·æœ¬
        baseline_sample = baseline_df.loc[selected_baseline]

        # æ–°å¢ï¼šåŸºå‡†æ ·æœ¬æ€§èƒ½å±•ç¤ºæ ·å¼ä¼˜åŒ–
        st.markdown(f"""
        <div style="background:#f0f2f6;padding:10px;border-radius:5px">
            ğŸ“Š åŸºå‡†æ€§èƒ½å€¼ï¼š<span style="color:#0068c9;font-weight:bold">{baseline_sample['JV_default_PCE']:.4f}</span>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        # æ–°å¢ï¼šç‰¹å¾é€‰æ‹©è¯´æ˜
        st.markdown("### ç‰¹å¾é€‰æ‹©")
        st.caption("è¯·å…ˆé€‰æ‹©éœ€è¦è°ƒæ•´çš„ç‰¹å¾")

# æ–°å¢ï¼šç‰¹å¾è¾“å…¥åˆ†ç»„
with st.expander("ğŸ”§ ç‰¹å¾è°ƒæ•´", expanded=True):
    # åˆå§‹åŒ–å¯ç¼–è¾‘çš„ç‰¹å¾åˆ—è¡¨
    editable_features_compounds = [col for col in baseline_sample.index if col.startswith('Perovskite_additives_compounds')]
    editable_features_concentrations = [col for col in baseline_sample.index if col.startswith('Perovskite_additives_concentrations')]

    col_compound, col_concentration = st.columns(2)
    with col_compound:
        selected_compound = st.selectbox("åŒ–åˆç‰©ç‰¹å¾", editable_features_compounds,
                                       index=0, key='compound_select')
    with col_concentration:
        selected_concentration = st.selectbox("æµ“åº¦ç‰¹å¾", editable_features_concentrations,
                                            index=0, key='concentration_select')

    # è¾“å…¥å­—æ®µå¸ƒå±€ä¼˜åŒ–
    input_col1, input_col2 = st.columns(2)
    input_values = {}
    with input_col1:
        input_values[selected_compound] = st.number_input(
            f"{selected_compound}", 
            value=int(baseline_sample[selected_compound]),
            min_value=0, max_value=100, step=1,
            help="è°ƒæ•´åŒ–åˆç‰©ç‰¹å¾å€¼ (0-100)"
        )
    with input_col2:
        input_values[selected_concentration] = st.number_input(
            f"{selected_concentration}",
            value=int(baseline_sample[selected_concentration]),
            min_value=0, max_value=100, step=1,
            help="è°ƒæ•´æµ“åº¦ç‰¹å¾å€¼ (0-100)"
        )

# æ–°å¢ï¼šé¢„æµ‹æŒ‰é’®æ ·å¼ä¼˜åŒ–
predict_col, _ = st.columns([2, 8])
with predict_col:
    if st.button("ğŸš€ å¼€å§‹é¢„æµ‹", type="primary", use_container_width=True):
        # åˆ›å»ºé¢„æµ‹è¾“å…¥æ•°æ®
        input_data = baseline_sample.copy()
        for feature, value in input_values.items():
            input_data[feature] = value
        
        # è¿›è¡Œé¢„æµ‹
        input_data = input_data.drop('JV_default_PCE')  # ç§»é™¤ç›®æ ‡å˜é‡
        input_data = pd.DataFrame([input_data])  # è½¬æ¢ä¸ºDataFrame
        prediction = model.predict(input_data)[0]
        
        # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
        st.success(f"é¢„æµ‹çš„ç›®æ ‡æ€§èƒ½ (JV_default_PCE): {prediction:.4f}")

        # æ–°å¢ï¼šè®¡ç®—æ¨¡å‹æ€§èƒ½æŒ‡æ ‡
        y_pred_train = model.predict(X_train)
        y_pred_val = model.predict(X_val)
        y_pred_test = model.predict(X_test)
        
        train_mse = mean_squared_error(y_train, y_pred_train)
        val_mse = mean_squared_error(y_val, y_pred_val)
        test_mse = mean_squared_error(y_test, y_pred_test)
        
        train_r2 = r2_score(y_train, y_pred_train)
        val_r2 = r2_score(y_val, y_pred_val)
        test_r2 = r2_score(y_test, y_pred_test)
        
        train_mae = mean_absolute_error(y_train, y_pred_train)
        val_mae = mean_absolute_error(y_val, y_pred_val)
        test_mae = mean_absolute_error(y_test, y_pred_test)

        # æ–°å¢ï¼šä¿å­˜é¢„æµ‹ç»“æœã€æ¨¡å‹æ€§èƒ½æŒ‡æ ‡ã€åŸºå‡†æ ·æœ¬å’Œç”¨æˆ·ä¿®æ”¹é¡¹åˆ°ä¸´æ—¶æ–‡ä»¶
        temp_data = {
            'prediction': prediction,
            'train_mse': train_mse, 'val_mse': val_mse, 'test_mse': test_mse,
            'train_r2': train_r2, 'val_r2': val_r2, 'test_r2': test_r2,
            'train_mae': train_mae, 'val_mae': val_mae, 'test_mae': test_mae,
            'baseline_sample': baseline_sample.to_dict(),
            'input_values': input_values
        }
        
        temp_file_path = 'e:/newml/temp_prediction_data.json'
        with open(temp_file_path, 'w') as f:
            json.dump(temp_data, f)

        # å¯¼å‡ºé¢„æµ‹æ•°æ®
        prediction_df = input_data.copy()
        prediction_df['Predicted_JV_default_PCE'] = prediction
        csv_prediction = prediction_df.to_csv(index=False).encode('utf-8')
        st.download_button(
            "å¯¼å‡ºé¢„æµ‹æ•°æ®",
            data=csv_prediction,
            file_name="prediction_result.csv",
            mime="text/csv"
        )
        
        # å¯¼å‡ºåŸå§‹baselineæ ·æœ¬
        baseline_export_df = pd.DataFrame([baseline_sample])
        csv_baseline = baseline_export_df.to_csv(index=False).encode('utf-8')
        st.download_button(
            "å¯¼å‡ºåŸå§‹Baseline",
            data=csv_baseline,
            file_name="baseline_sample.csv",
            mime="text/csv"
        )

        # SHAP åˆ†æ
        st.header("SHAP åˆ†æ")
        explainer = shap.TreeExplainer(model)
        shap_values = explainer.shap_values(input_data)
        
        # å¯è§†åŒ– SHAP å€¼
        st.subheader("SHAP å€¼")
        shap.force_plot(explainer.expected_value, shap_values, input_data, show=False)
        st.pyplot(plt.gcf())
        plt.close()

        # æ­£è´Ÿè´¡çŒ®å¯è§†åŒ–
        st.subheader("æ­£è´Ÿè´¡çŒ®")
        shap.summary_plot(shap_values, input_data, plot_type="bar", show=False)
        st.pyplot(plt.gcf())
        plt.close()

        # æ–°å¢ï¼šç”Ÿæˆå®éªŒè®¾è®¡æ–¹æ¡ˆ
        st.header("å®éªŒè®¾è®¡åŠ©æ‰‹")
        st.subheader("æ­£åœ¨ç”Ÿæˆå®éªŒè®¾è®¡æ–¹æ¡ˆ...")
        progress_bar = st.progress(0)

        # ä»ä¸´æ—¶æ–‡ä»¶ä¸­è¯»å–æ•°æ®
        temp_file_path = 'e:/newml/temp_prediction_data.json'
        with open(temp_file_path, 'r') as f:
            temp_data = json.load(f)

        prediction = temp_data['prediction']
        baseline_sample = pd.Series(temp_data['baseline_sample'])
        input_values = temp_data['input_values']

        # æ–°å¢ï¼šåˆå§‹åŒ–ZhipuAIå®¢æˆ·ç«¯
        client = ZhipuAI(api_key="4dc712e71da74ead8f16651dccbf71bf.BPESIGBsJhKo9rYz")

        # ä¿®æ”¹ï¼šä¼˜åŒ–åçš„promptç»“æ„ï¼Œå¢åŠ æ ¼å¼è¦æ±‚ï¼Œæ˜ç¡®ä¸­æ–‡è¾“å‡º
        response = client.chat.completions.create(
            model="glm-4-air-250414",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªææ–™ç§‘å­¦å®éªŒè®¾è®¡ä¸“å®¶ï¼Œè¯·ç”¨ä¸­æ–‡ç”Ÿæˆè§„èŒƒçš„å®éªŒæ–¹æ¡ˆ"},
                {"role": "user", "content": f"""è¯·åŸºäºä»¥ä¸‹å®éªŒæ•°æ®ç”Ÿæˆè¯¦ç»†çš„ä¸­æ–‡å®éªŒè®¾è®¡æ–¹æ¡ˆï¼š
# åŸºç¡€æ•°æ®
1. åŸºå‡†æ€§èƒ½å€¼ï¼š{baseline_sample['JV_default_PCE']:.4f}
2. è°ƒæ•´ç‰¹å¾ï¼š{', '.join(input_values.keys())}
3. ç‰¹å¾è°ƒæ•´å€¼ï¼š{', '.join(map(str, input_values.values()))}
4. é¢„æµ‹æ€§èƒ½å€¼ï¼š{prediction:.4f}

# æ–¹æ¡ˆè¦æ±‚
## å®éªŒæ­¥éª¤
- åˆ†æ­¥éª¤æè¿°å…·ä½“æ“ä½œæµç¨‹
- åŒ…å«ææ–™å‡†å¤‡å’Œä»ªå™¨è®¾ç½®

## å‚æ•°è®¾ç½®
- è¯´æ˜æ¯ä¸ªè°ƒæ•´å‚æ•°çš„è®¾ç½®ä¾æ®
- ç»“åˆé¢†åŸŸçŸ¥è¯†è§£é‡Šå‚æ•°åˆç†æ€§

## ç»“æœé¢„æµ‹
- é¢„æµ‹å¯èƒ½çš„ç»“æœèŒƒå›´ï¼ˆç½®ä¿¡åŒºé—´ï¼‰
- åˆ†æä¸åŒç»“æœçš„å¯èƒ½æ€§

## éªŒè¯æ–¹æ³•
- æå‡º3ç§ä¸åŒçš„éªŒè¯æ–¹æ¡ˆ
- åŒ…å«å¯¹ç…§å®éªŒè®¾è®¡

## é£é™©è¯„ä¼°
- åˆ—å‡º3ä¸ªä¸»è¦é£é™©ç‚¹
- æ¯ä¸ªé£é™©ç‚¹éœ€æä¾›åº”å¯¹æªæ–½

è¯·ä½¿ç”¨ä»¥ä¸‹Markdownæ ¼å¼æ¨¡æ¿ï¼š
### å®éªŒè®¾è®¡æ–¹æ¡ˆ
#### 1. å®éªŒæ­¥éª¤
...
#### 2. å‚æ•°è®¾ç½®ä¾æ®
...
"""}
            ]
        )

        # æ›´æ–°è¿›åº¦æ¡
        progress_bar.progress(100)

        # ä¿®æ”¹ï¼šå¢å¤§æ–‡æœ¬åŒºåŸŸé«˜åº¦å¹¶æ·»åŠ å¯¼å‡ºåŠŸèƒ½
        st.subheader("ç”Ÿæˆçš„å®éªŒè®¾è®¡æ–¹æ¡ˆ")
        experiment_design = response.choices[0].message.content
        st.text_area("å®éªŒæ–¹æ¡ˆå†…å®¹", 
                   value=experiment_design, 
                   height=400,  # é«˜åº¦ä»300å¢åŠ åˆ°400
                   key="experiment_design")
        
        # æ–°å¢ï¼šå®éªŒæ–¹æ¡ˆå¯¼å‡ºåŠŸèƒ½
        st.download_button(
            label="ğŸ“¥ å¯¼å‡ºå®éªŒæ–¹æ¡ˆ",
            data=experiment_design,
            file_name="experiment_design.md",
            mime="text/markdown",
            key="export_design"
        )

# é¢„æµ‹ç»“æœå±•ç¤ºä¼˜åŒ–
if prediction is not None:
    st.markdown(f"""
    <div style="background:#e6f4ea;padding:20px;border-radius:10px;margin-top:20px">
        <h3 style="color:#137333">ğŸ“ˆ é¢„æµ‹ç»“æœ</h3>
        <p style="font-size:1.2rem">é¢„æµ‹æ€§èƒ½å€¼ï¼š<span style="color:#137333;font-weight:bold">{prediction:.4f}</span></p>
    </div>
    """, unsafe_allow_html=True)

    # å¯¼å‡ºæŒ‰é’®å¸ƒå±€ä¼˜åŒ–
    export_col1, export_col2 = st.columns(2)
    with export_col1:
        st.download_button(
            "ğŸ“¥ å¯¼å‡ºé¢„æµ‹æ•°æ®",
            data=csv_prediction,
            file_name="prediction_result.csv",
            mime="text/csv",
            use_container_width=True
        )
    with export_col2:
        st.download_button(
            "ğŸ“¥ å¯¼å‡ºåŸå§‹Baseline",
            data=csv_baseline,
            file_name="baseline_sample.csv",
            mime="text/csv",
            use_container_width=True
        )

# ä¾§è¾¹æ ä¼˜åŒ–
st.sidebar.markdown("## å…¨å±€SHAPåˆ†æé…ç½®")
selected_feature = st.sidebar.selectbox("åˆ†æç‰¹å¾", X.columns, 
                                      help="é€‰æ‹©éœ€è¦åˆ†æçš„ç‰¹å¾é‡è¦æ€§")
if selected_feature:
    with st.sidebar.expander("åˆ†æè¯´æ˜"):
        st.write("SHAPå€¼è¡¨ç¤ºç‰¹å¾å¯¹é¢„æµ‹ç»“æœçš„è´¡çŒ®ç¨‹åº¦ï¼š")
        st.markdown("- ğŸ”´ æ­£å€¼ï¼šæå‡é¢„æµ‹ç»“æœ")
        st.markdown("- ğŸ”µ è´Ÿå€¼ï¼šé™ä½é¢„æµ‹ç»“æœ")
    
    # æ–°å¢ï¼šåˆ†æåŠ è½½æç¤º
    with st.spinner("æ­£åœ¨ç”ŸæˆSHAPåˆ†æ..."):
        explainer = shap.TreeExplainer(model)
        shap_values = explainer.shap_values(X)
        
        # ç¡®ä¿ shap_values æ˜¯ä¸€ä¸ªçŸ©é˜µ
        if len(shap_values.shape) == 1:
            shap_values = shap_values.reshape(-1, 1)
        
        st.sidebar.subheader(f"{selected_feature} çš„ SHAP åˆ†æ")
        shap.dependence_plot(selected_feature, shap_values, X.values, feature_names=X.columns.tolist(), show=False)
        st.sidebar.pyplot(plt.gcf())
        plt.close()
