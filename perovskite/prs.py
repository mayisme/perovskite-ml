import streamlit as st
import pandas as pd
import numpy as np
from rdkit import Chem
from rdkit.Chem import rdFingerprintGenerator
import joblib
import json
from typing import List, Dict, Any
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import shap
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import time
import threading
import queue
import os
from pathlib import Path

# é¡µé¢è®¾ç½®
st.set_page_config(
    page_title="åˆ†å­æ€§è´¨é¢„æµ‹ä¸æ¨¡å‹åˆ†æå¹³å°",
    page_icon="ğŸ§ª",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ–æŒ‡çº¹ç”Ÿæˆå™¨
def initialize_fingerprint_generator():
    return rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=2048)

ZERO_FP_LIST = [0] * 2048

def smiles_to_fp_list(smiles: str, mfpgen) -> List[int]:
    """å°†SMILESå­—ç¬¦ä¸²è½¬æ¢ä¸º2048ä½æ‘©æ ¹æŒ‡çº¹çš„æ•´æ•°åˆ—è¡¨"""
    # é¢„å¤„ç†SMILESå­—ç¬¦ä¸²ï¼Œå¤„ç†ä¸€äº›å¸¸è§é—®é¢˜
    smiles = smiles.strip()
    
    # å¦‚æœå­—ç¬¦ä¸²ä¸ºç©ºï¼Œè¿”å›é›¶æŒ‡çº¹
    if not smiles:
        return ZERO_FP_LIST
    
    # ç›´æ¥å°è¯•è§£æSMILES
    try:
        mol = Chem.MolFromSmiles(smiles)
        if mol is not None:
            # æ£€æŸ¥åˆ†å­æ˜¯å¦æœ‰æ•ˆï¼ˆä¾‹å¦‚ï¼Œæ²¡æœ‰ä¸åˆç†çš„ä»·æ€ï¼‰
            try:
                Chem.SanitizeMol(mol)
                fp = mfpgen.GetFingerprint(mol)
                return list(fp)
            except Exception as sanitize_error:
                st.warning(f"SMILES '{smiles}' åˆ†å­æ— æ³•è¢«è§„èŒƒåŒ–: {str(sanitize_error)}")
        else:
            st.warning(f"æ— æ•ˆçš„SMILES: {smiles}")
    except Exception as e:
        # è®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­ç¨‹åº
        st.warning(f"è§£æSMILESæ—¶å‡ºé”™ '{smiles}': {str(e)}")
        pass
    
    # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•å…¶ä»–å¤„ç†æ–¹å¼
    try:
        # ç§»é™¤æœ«å°¾å¯èƒ½å­˜åœ¨çš„é€—å·ï¼ˆåªç§»é™¤æœ€åçš„é€—å·ï¼‰
        if smiles.endswith(','):
            cleaned_smiles = smiles.rstrip(',')
            mol = Chem.MolFromSmiles(cleaned_smiles)
            if mol is not None:
                # æ£€æŸ¥åˆ†å­æ˜¯å¦æœ‰æ•ˆ
                try:
                    Chem.SanitizeMol(mol)
                    fp = mfpgen.GetFingerprint(mol)
                    return list(fp)
                except Exception as sanitize_error:
                    st.warning(f"æ¸…ç†åçš„SMILES '{cleaned_smiles}' åˆ†å­æ— æ³•è¢«è§„èŒƒåŒ–: {str(sanitize_error)}")
            else:
                st.warning(f"æ¸…ç†åä»ç„¶æ— æ•ˆçš„SMILES: {cleaned_smiles}")
    except Exception as e:
        # è®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­ç¨‹åº
        st.warning(f"æ¸…ç†SMILESæ—¶å‡ºé”™ '{smiles}': {str(e)}")
        pass
    
    # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œè¿”å›é›¶æŒ‡çº¹
    st.warning(f"æ— æ³•ä»SMILESç”ŸæˆæŒ‡çº¹: {smiles}ï¼Œä½¿ç”¨é›¶æŒ‡çº¹")
    return ZERO_FP_LIST

def merge_multiple_fps(smiles_cell, mfpgen) -> List[int]:
    """å¤„ç†å¯èƒ½åŒ…å«å¤šä¸ªSMILESå­—ç¬¦ä¸²çš„å•å…ƒæ ¼ï¼Œæ”¯æŒç‚¹åˆ†åˆ†å­å’Œåˆ†å·åˆ†éš”çš„å¤šä¸ªSMILES"""
    # å¤„ç†è¾“å…¥ä¸ºå­—ç¬¦ä¸²çš„æƒ…å†µ
    smiles_input = str(smiles_cell).strip()
    
    # å¦‚æœè¾“å…¥ä¸ºç©ºï¼Œè¿”å›é›¶æŒ‡çº¹
    if not smiles_input:
        return ZERO_FP_LIST
    
    # æ ¹æ®æ‚¨çš„è¯´æ˜ï¼š
    # - ä½¿ç”¨åˆ†å·(;)åŒºåˆ†ä¸åŒçš„é¢„æµ‹ä»»åŠ¡
    # - ä½¿ç”¨ç‚¹(.)è¿æ¥åŒä¸€é¢„æµ‹ä»»åŠ¡ä¸­çš„ä¸åŒåˆ†å­ç‰‡æ®µ
    # - ä½¿ç”¨é€—å·(,)åŒºåˆ†åŒä¸€è¡Œä¸­çš„å¤šä¸ªé¢„æµ‹ä»»åŠ¡ï¼ˆåœ¨tab1ä¸­ä½¿ç”¨ï¼‰
    task_groups = [task.strip() for task in smiles_input.split(';') if task.strip()]
    
    if not task_groups:
        return ZERO_FP_LIST
    
    valid_fps = []
    error_messages = []
    
    for task in task_groups:
        # æ¯ä¸ªä»»åŠ¡ç»„ä¸­å¯èƒ½åŒ…å«å¤šä¸ªåˆ†å­ç‰‡æ®µï¼ˆå¦‚Br.CC[NH3+]c1ccccc1ï¼‰
        # è¿™äº›ç‰‡æ®µéœ€è¦è¢«å•ç‹¬è½¬æ¢ä¸ºæŒ‡çº¹åå†åˆå¹¶
        fragments = [frag.strip() for frag in task.split('.') if frag.strip()]
        
        fragment_fps = []
        for frag in fragments:
            try:
                fp = smiles_to_fp_list(frag, mfpgen)
                # åªæœ‰éé›¶æŒ‡çº¹æ‰åŠ å…¥ï¼ˆé¿å…å…¨é›¶æŒ‡çº¹å¹²æ‰°ï¼‰
                if any(fp):
                    fragment_fps.append(fp)
                else:
                    error_messages.append(f"æ— æ³•ä¸ºåˆ†å­ç‰‡æ®µç”Ÿæˆæœ‰æ•ˆæŒ‡çº¹: {frag}")
            except Exception as e:
                error_msg = f"å¤„ç†åˆ†å­ç‰‡æ®µ '{frag}' æ—¶å‡ºé”™: {str(e)}"
                error_messages.append(error_msg)
                # å¿½ç•¥å•ä¸ªåˆ†å­ç‰‡æ®µçš„é”™è¯¯ï¼Œç»§ç»­å¤„ç†å…¶ä»–ç‰‡æ®µ
                continue
        
        # å¦‚æœæˆåŠŸç”Ÿæˆäº†æ‰€æœ‰åˆ†å­ç‰‡æ®µçš„æŒ‡çº¹ï¼Œå°†å®ƒä»¬åˆå¹¶
        if fragment_fps:
            arr_fps = np.array(fragment_fps)
            merged_fp = np.bitwise_or.reduce(arr_fps, axis=0)
            valid_fps.append(merged_fp.tolist())
        else:
            error_messages.append(f"ä»»åŠ¡ '{task}' ä¸­çš„æ‰€æœ‰åˆ†å­ç‰‡æ®µéƒ½æ— æ³•ç”Ÿæˆæœ‰æ•ˆæŒ‡çº¹")
    
    # å¦‚æœæœ‰é”™è¯¯ä¿¡æ¯ï¼Œæ±‡æ€»æ˜¾ç¤º
    if error_messages:
        st.warning(f"åœ¨å¤„ç†å¤šä¸ªSMILESæ—¶é‡åˆ°ä»¥ä¸‹é—®é¢˜:\n" + "\n".join(error_messages))
    
    # å¦‚æœæœ‰æœ‰æ•ˆçš„æŒ‡çº¹ï¼Œåˆå¹¶å®ƒä»¬
    if valid_fps:
        arr_fps = np.array(valid_fps)
        merged_fp = np.bitwise_or.reduce(arr_fps, axis=0)
        return merged_fp.tolist()
    else:
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæŒ‡çº¹ï¼Œè¿”å›é›¶æŒ‡çº¹
        return ZERO_FP_LIST

# åŠ è½½æ•°æ®å’Œæ¨¡å‹
@st.cache_resource
def load_data_and_model():
    """åŠ è½½æ•°æ®å’Œæ¨¡å‹ï¼Œä½¿ç”¨ç¼“å­˜æé«˜æ€§èƒ½"""
    try:
        df = pd.read_csv('3.csv')
        model = joblib.load(r'trained_model_xgboost.pkl')
        return df, model
    except Exception as e:
        st.error(f"åŠ è½½æ•°æ®æˆ–æ¨¡å‹å¤±è´¥: {e}")
        return None, None

# åŠ è½½è¯„ä¼°æ•°æ®
@st.cache_resource
def load_evaluation_data():
    """åŠ è½½æ¨¡å‹è¯„ä¼°ç›¸å…³æ•°æ®"""
    try:
        eval_df = pd.read_csv('output_20250826_130253/evaluation_results_xgboost.csv')
        feat_df = pd.read_csv('output_20250826_130253/feature_importance_xgboost.csv')
        pred_df = pd.read_csv('output_20250826_130253/model_predictions_xgboost.csv')
        return eval_df, feat_df, pred_df
    except Exception as e:
        st.error(f"åŠ è½½è¯„ä¼°æ•°æ®å¤±è´¥: {e}")
        return None, None, None

# å¤„ç†ç‰¹å¾é‡è¦æ€§æ•°æ® - åˆå¹¶fp_å¼€å¤´çš„ç‰¹å¾
def process_feature_importance(feat_df):
    """å¤„ç†ç‰¹å¾é‡è¦æ€§æ•°æ®ï¼Œåˆå¹¶fp_å¼€å¤´çš„ç‰¹å¾"""
    # åˆ†ç¦»fpç‰¹å¾å’Œéfpç‰¹å¾
    fp_features = feat_df[feat_df['raw_name'].str.startswith('fp_')]
    non_fp_features = feat_df[~feat_df['raw_name'].str.startswith('fp_')]
    
    # è®¡ç®—fpç‰¹å¾çš„æ€»é‡è¦æ€§
    fp_total_importance = fp_features['importance'].sum()
    
    # åˆ›å»ºæ–°çš„ç‰¹å¾é‡è¦æ€§DataFrame
    processed_features = non_fp_features.copy()
    
    # æ·»åŠ åˆå¹¶åçš„fpç‰¹å¾
    fp_row = pd.DataFrame({
        'raw_name': ['fp_all_combined'],
        'importance': [fp_total_importance]
    })
    
    processed_features = pd.concat([processed_features, fp_row], ignore_index=True)
    
    # æŒ‰é‡è¦æ€§æ’åº
    processed_features = processed_features.sort_values('importance', ascending=False)
    
    return processed_features

# ç”ŸæˆSHAPåˆ†æå›¾
def generate_shap_plot(model, X_data, feature_names):
    """ç”ŸæˆSHAPç‰¹å¾é‡è¦æ€§æ‘˜è¦å›¾"""
    try:
        # è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'STHeiti', 'Songti SC', 'Arial Unicode MS', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # åˆ›å»ºSHAPè§£é‡Šå™¨
        explainer = shap.TreeExplainer(model)
        
        # è®¡ç®—SHAPå€¼ï¼ˆä½¿ç”¨å­é‡‡æ ·ä»¥æé«˜æ€§èƒ½ï¼‰
        sample_size = min(100, len(X_data))
        X_sample = X_data[:sample_size]
        shap_values = explainer.shap_values(X_sample)
        
        # ç¡®ä¿shap_valuesæ˜¯æ­£ç¡®çš„å½¢çŠ¶
        if isinstance(shap_values, list):
            # å¯¹äºæŸäº›æ¨¡å‹ï¼Œshap_valueså¯èƒ½æ˜¯ä¸€ä¸ªåˆ—è¡¨
            shap_values = shap_values[0]
        
        # å¤„ç†ç‰¹å¾åç§° - åˆå¹¶fp_å¼€å¤´çš„ç‰¹å¾
        fp_mask = [name.startswith('fp_') for name in feature_names]
        non_fp_indices = [i for i, is_fp in enumerate(fp_mask) if not is_fp]
        fp_indices = [i for i, is_fp in enumerate(fp_mask) if is_fp]
        
        # å¦‚æœæœ‰fpç‰¹å¾ï¼Œåˆå¹¶å®ƒä»¬
        if fp_indices:
            # åˆå¹¶fpç‰¹å¾çš„SHAPå€¼
            fp_shap_sum = np.sum(shap_values[:, fp_indices], axis=1)
            
            # åˆ›å»ºæ–°çš„SHAPå€¼æ•°ç»„
            new_shap_values = np.zeros((sample_size, len(non_fp_indices) + 1))
            new_shap_values[:, 0] = fp_shap_sum  # ç¬¬ä¸€ä¸ªä½ç½®æ”¾åˆå¹¶çš„fpç‰¹å¾
            new_shap_values[:, 1:] = shap_values[:, non_fp_indices]
            
            # åˆ›å»ºæ–°çš„ç‰¹å¾åç§°
            new_feature_names = ['fp_all_combined'] + [feature_names[i] for i in non_fp_indices]
            
            # ç¡®ä¿æ•°æ®ä¹Ÿæ˜¯ç›¸åº”å½¢çŠ¶
            X_sample_modified = np.zeros((sample_size, len(non_fp_indices) + 1))
            X_sample_modified[:, 0] = np.sum(X_sample[:, fp_indices], axis=1)  # åˆå¹¶çš„fpç‰¹å¾
            X_sample_modified[:, 1:] = X_sample[:, non_fp_indices]
        else:
            new_shap_values = shap_values
            new_feature_names = feature_names
            X_sample_modified = X_sample
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if not os.path.exists('shap_plots'):
            os.makedirs('shap_plots')
        
        # 1. åˆ›å»ºSHAPæ‘˜è¦å›¾
        plt.figure(figsize=(12, 10))
        shap.summary_plot(
            new_shap_values, 
            X_sample_modified, 
            feature_names=new_feature_names,
            max_display=20,  # æ˜¾ç¤ºå‰20ä¸ªæœ€é‡è¦çš„ç‰¹å¾
            show=False
        )
        
        plt.title('SHAPç‰¹å¾é‡è¦æ€§æ‘˜è¦å›¾ï¼ˆfpç‰¹å¾å·²åˆå¹¶ï¼‰')
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        summary_plot_path = os.path.join('shap_plots', 'shap_summary_plot.png')
        plt.savefig(summary_plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. åˆ›å»ºSHAPçƒ­åŠ›å›¾
        plt.figure(figsize=(12, 10))
        shap.summary_plot(
            new_shap_values,
            X_sample_modified,
            feature_names=new_feature_names,
            plot_type="compact_dot",
            max_display=20,
            show=False
        )
        
        plt.title('SHAPç‰¹å¾é‡è¦æ€§çƒ­åŠ›å›¾ï¼ˆfpç‰¹å¾å·²åˆå¹¶ï¼‰')
        plt.tight_layout()
        
        # ä¿å­˜çƒ­åŠ›å›¾
        heatmap_plot_path = os.path.join('shap_plots', 'shap_heatmap_plot.png')
        plt.savefig(heatmap_plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. åˆ›å»ºSHAPèœ‚ç¾¤å›¾
        plt.figure(figsize=(12, 10))
        shap.summary_plot(
            new_shap_values,
            X_sample_modified,
            feature_names=new_feature_names,
            plot_type="violin",
            max_display=20,
            show=False
        )
        
        plt.title('SHAPç‰¹å¾é‡è¦æ€§å°æç´å›¾ï¼ˆfpç‰¹å¾å·²åˆå¹¶ï¼‰')
        plt.tight_layout()
        
        # ä¿å­˜èœ‚ç¾¤å›¾
        violin_plot_path = os.path.join('shap_plots', 'shap_violin_plot.png')
        plt.savefig(violin_plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        # 4. åˆ›å»ºç‰¹å¾é‡è¦æ€§ç®±çº¿å›¾
        # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„ç»å¯¹SHAPå€¼ï¼ˆè¡¨ç¤ºé‡è¦æ€§ï¼‰
        abs_shap_values = np.abs(new_shap_values)
        feature_importance = np.mean(abs_shap_values, axis=0)
        
        # åˆ›å»ºç®±çº¿å›¾æ•°æ®
        fig, ax = plt.subplots(figsize=(12, 10))
        
        # ä¸ºå‰10ä¸ªæœ€é‡è¦çš„ç‰¹å¾åˆ›å»ºç®±çº¿å›¾
        top_features_idx = np.argsort(feature_importance)[-10:]  # å–å‰10ä¸ªç‰¹å¾
        box_data = [new_shap_values[:, i] for i in top_features_idx]
        box_labels = [new_feature_names[i] for i in top_features_idx]
        
        # ç»˜åˆ¶ç®±çº¿å›¾
        bp = ax.boxplot(box_data, labels=box_labels, vert=False, patch_artist=True)
        
        # è®¾ç½®é¢œè‰²
        colors = plt.cm.Set3(np.linspace(0, 1, len(box_labels)))
        for patch, color in zip(bp['boxes'], colors):
            patch.set_facecolor(color)
        
        ax.set_xlabel('SHAPå€¼')
        ax.set_title('å‰10ä¸ªæœ€é‡è¦ç‰¹å¾çš„SHAPå€¼åˆ†å¸ƒç®±çº¿å›¾')
        plt.tight_layout()
        
        # ä¿å­˜ç®±çº¿å›¾
        boxplot_path = os.path.join('shap_plots', 'shap_boxplot.png')
        plt.savefig(boxplot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        return {
            'summary': summary_plot_path,
            'heatmap': heatmap_plot_path,
            'violin': violin_plot_path,
            'boxplot': boxplot_path
        }
        
    except Exception as e:
        st.error(f"SHAPåˆ†æå¤±è´¥: {e}")
        return None

# é€‰æ‹©åŸºå‡†è¡Œ
def select_baseline_row(df, pce_threshold=15.0):
    """æ ¹æ®PCEæ€§èƒ½é€‰æ‹©åŸºå‡†è¡Œ"""
    candidates = df[df['JV_default_PCE'] >= pce_threshold]
    
    if len(candidates) == 0:
        st.warning(f"æ²¡æœ‰æ‰¾åˆ°PCEé«˜äº{pce_threshold}çš„è¡Œï¼Œå°†ä½¿ç”¨PCEæœ€é«˜çš„è¡Œä½œä¸ºåŸºå‡†")
        return df.loc[df['JV_default_PCE'].idxmax()].copy()
    
    median_pce = candidates['JV_default_PCE'].median()
    closest_idx = (candidates['JV_default_PCE'] - median_pce).abs().idxmin()
    
    baseline_row = candidates.loc[closest_idx].copy()
    st.success(f"é€‰æ‹©çš„åŸºå‡†è¡ŒID: {closest_idx}, åŸå§‹PCE: {baseline_row['JV_default_PCE']:.2f}%")
    
    return baseline_row

# é¢„æµ‹å‡½æ•°
def predict_with_custom_smiles(baseline_row, smiles, model, mfpgen):
    """ç”¨è‡ªå®šä¹‰SMILESä¿®æ”¹åŸºå‡†è¡Œçš„æŒ‡çº¹åˆ—å¹¶è¿›è¡Œé¢„æµ‹"""
    try:
        new_fp = merge_multiple_fps(smiles, mfpgen)
        
        # æ£€æŸ¥æŒ‡çº¹æ˜¯å¦å…¨ä¸ºé›¶ï¼ˆè¡¨ç¤ºæ‰€æœ‰SMILESéƒ½æ— æ•ˆï¼‰
        if not any(new_fp):
            # æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            if ';' in str(smiles):
                raise ValueError("æ— æ³•ä»æä¾›çš„SMILESç”Ÿæˆæœ‰æ•ˆæŒ‡çº¹ï¼Œå¯èƒ½æ˜¯å› ä¸ºæ‰€æœ‰SMILESæ ¼å¼éƒ½ä¸æ­£ç¡®ã€‚"
                               "è¯·æ£€æŸ¥æ¯ä¸ªSMILESå­—ç¬¦ä¸²æ˜¯å¦æœ‰æ•ˆï¼Œç‰¹åˆ«æ˜¯ç”¨åˆ†å·åˆ†éš”çš„éƒ¨åˆ†ã€‚")
            else:
                raise ValueError("æ— æ³•ä»æä¾›çš„SMILESç”Ÿæˆæœ‰æ•ˆæŒ‡çº¹ï¼Œå¯èƒ½æ˜¯å› ä¸ºSMILESæ ¼å¼ä¸æ­£ç¡®ã€‚"
                               "è¯·æ£€æŸ¥è¾“å…¥çš„SMILESå­—ç¬¦ä¸²æ˜¯å¦ç¬¦åˆè§„èŒƒã€‚")
        
        modified_row = baseline_row.copy()
        fp_cols = [col for col in modified_row.index if col.startswith('fp_')]
        
        # æ£€æŸ¥ç‰¹å¾åˆ—æ•°é‡æ˜¯å¦åŒ¹é…
        if len(fp_cols) != len(new_fp):
            raise ValueError(f"æŒ‡çº¹é•¿åº¦ä¸åŒ¹é…: æœŸæœ› {len(fp_cols)} ä½ï¼Œå®é™…å¾—åˆ° {len(new_fp)} ä½ã€‚"
                           f"è¯·ç¡®ä¿ä½¿ç”¨çš„æŒ‡çº¹ç”Ÿæˆå™¨å‚æ•°ä¸è®­ç»ƒæ—¶ä¸€è‡´ã€‚")
            
        modified_row[fp_cols] = new_fp
        
        if 'JV_default_PCE' in modified_row.index:
            X_pred = modified_row.drop('JV_default_PCE').values.reshape(1, -1)
        else:
            X_pred = modified_row.values.reshape(1, -1)
        
        predicted_pce = model.predict(X_pred)[0]
        
        # ç¡®ä¿è¿”å›çš„æ˜¯PythonåŸç”Ÿfloatç±»å‹ï¼Œè€Œä¸æ˜¯numpy.floatç±»å‹
        return float(predicted_pce), modified_row
    except ValueError as ve:
        raise ve
    except Exception as e:
        raise ValueError(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

# æ‰¹é‡å¤„ç†å‡½æ•°
def process_batch_file(file_content, baseline_row, model, mfpgen, progress_queue):
    """å¤„ç†æ‰¹é‡SMILESæ–‡ä»¶"""
    results = []
    errors = []
    lines = file_content.decode('utf-8').split('\n')
    
    # è®¡ç®—æ€»ä»»åŠ¡æ•°ï¼ˆè€ƒè™‘é€—å·åˆ†éš”çš„ä»»åŠ¡ï¼‰
    total_tasks = 0
    for line in lines:
        line = line.strip()
        if not line or line.startswith('#'):
            continue
        # æ¯è¡Œä¸­ç”¨é€—å·åˆ†éš”çš„ä»»åŠ¡æ•°
        tasks_in_line = [task.strip() for task in line.split(',') if task.strip()]
        total_tasks += len(tasks_in_line)
    
    processed = 0
    task_id = 1
    
    # æ˜¾ç¤ºæ€»ä»»åŠ¡æ•°
    progress_queue.put((0, total_tasks, f"å¼€å§‹å¤„ç† {total_tasks} ä¸ªä»»åŠ¡"))
    
    for i, line in enumerate(lines):
        line = line.strip()
        if not line or line.startswith('#'):
            continue
            
        # æ ¹æ®æ‚¨çš„è¯´æ˜ï¼šä½¿ç”¨é€—å·(,)åŒºåˆ†ä¸åŒçš„é¢„æµ‹ä»»åŠ¡ï¼Œä½¿ç”¨åˆ†å·(;)åŒºåˆ†åŒä¸€é¢„æµ‹ä»»åŠ¡ä¸­çš„ä¸åŒSMILESå­—ç¬¦ä¸²
        # å°†æ¯è¡ŒæŒ‰é€—å·åˆ†å‰²æˆå¤šä¸ªä»»åŠ¡
        tasks = [task.strip() for task in line.split(',') if task.strip()]
        
        for task_smiles in tasks:
            try:
                predicted_pce, modified_row = predict_with_custom_smiles(
                    baseline_row, task_smiles, model, mfpgen
                )
                
                result = {
                    "task_id": task_id,
                    "smiles": task_smiles,
                    "predicted_pce": float(round(predicted_pce, 2)),  # ç¡®ä¿æ˜¯Python floatç±»å‹
                    "baseline_pce": float(round(baseline_row['JV_default_PCE'], 2)),  # ç¡®ä¿æ˜¯Python floatç±»å‹
                    "change": float(round(predicted_pce - baseline_row['JV_default_PCE'], 2)),  # ç¡®ä¿æ˜¯Python floatç±»å‹
                    "modified_row": modified_row.to_dict()
                }
                
                results.append(result)
                processed += 1
                task_id += 1
                progress_queue.put((processed, total_tasks, f"å¤„ç†ä¸­: {task_smiles}"))
                
            except Exception as e:
                error_msg = f"å¤„ç†ä»»åŠ¡ '{task_smiles}' æ—¶å‡ºé”™: {e}"
                errors.append(error_msg)
                processed += 1
                task_id += 1
                progress_queue.put((processed, total_tasks, f"å¤„ç†ä¸­: {task_smiles} (å¤±è´¥)"))
                
                # å‘é€é”™è¯¯ä¿¡æ¯åˆ°è¿›åº¦é˜Ÿåˆ—
                progress_queue.put(("error", error_msg))
    
    # å‘é€é”™è¯¯ä¿¡æ¯
    if errors:
        for error in errors:
            progress_queue.put(("error", error))
    
    results.sort(key=lambda x: x['change'], reverse=True)
    progress_queue.put(("complete", f"æˆåŠŸå¤„ç† {len(results)} ä¸ªä»»åŠ¡ï¼Œ{len(errors)} ä¸ªä»»åŠ¡å¤±è´¥"))
    
    return results

# åå°å¤„ç†çº¿ç¨‹
def process_in_background(file_content, baseline_row, model, mfpgen, progress_queue):
    """åå°å¤„ç†çº¿ç¨‹å‡½æ•°"""
    try:
        results = process_batch_file(file_content, baseline_row, model, mfpgen, progress_queue)
        progress_queue.put(("results", results))
    except Exception as e:
        progress_queue.put(("error", f"å¤„ç†å¤±è´¥: {e}"))

# è¿›åº¦æ›´æ–°å‡½æ•°
def update_progress(progress_queue, total_tasks):
    """æ›´æ–°å¤„ç†è¿›åº¦"""
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    while True:
        try:
            message = progress_queue.get(timeout=30)
            
            if message[0] == "complete":
                progress_bar.progress(1.0)
                status_text.success(message[1])
                break
            elif message[0] == "error":
                progress_bar.empty()
                status_text.error(message[1])
                break
            elif message[0] == "results":
                st.session_state.batch_results = message[1]
                break
            else:
                processed, total, status = message
                percent = processed / total
                progress_bar.progress(percent)
                status_text.info(f"{status} - è¿›åº¦: {percent*100:.1f}% ({processed}/{total})")
                
        except queue.Empty:
            break

# å¯¼å‡ºJSONå‡½æ•°
def export_to_json(results):
    """å°†ç»“æœå¯¼å‡ºä¸ºJSONæ–‡ä»¶"""
    export_data = []
    for result in results:
        export_result = result.copy()
        export_result.pop('modified_row', None)
        
        # ç¡®ä¿æ‰€æœ‰numpyæ•°æ®ç±»å‹éƒ½è¢«è½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹
        for key, value in export_result.items():
            if isinstance(value, (np.integer, np.floating)):
                export_result[key] = value.item()
            elif isinstance(value, np.ndarray):
                export_result[key] = value.tolist()
        
        export_data.append(export_result)
    
    return json.dumps(export_data, indent=2)

# ç‰¹å¾é‡è¦æ€§å¯è§†åŒ–
def plot_feature_importance(feat_df, top_n=20):
    """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾"""
    top_features = feat_df.nlargest(top_n, 'importance')
    
    fig = px.bar(
        top_features,
        x='importance',
        y='raw_name',
        orientation='h',
        title=f'Top {top_n} Feature Importances (fpç‰¹å¾å·²åˆå¹¶)',
        labels={'importance': 'Importance', 'raw_name': 'Features'}
    )
    
    fig.update_layout(height=600, yaxis={'categoryorder':'total ascending'})
    return fig

# æ¨¡å‹æ€§èƒ½è¯„ä¼°å¯è§†åŒ–
def plot_model_performance(eval_df, pred_df):
    """ç»˜åˆ¶æ¨¡å‹æ€§èƒ½è¯„ä¼°å›¾"""
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('Actual vs Predicted', 'Residuals Distribution', 'Prediction Error', 'Performance Metrics'),
        specs=[[{"colspan": 2}, None], [{}, {}]]
    )
    
    # å®é™…å€¼vsé¢„æµ‹å€¼
    fig.add_trace(go.Scatter(x=pred_df['Actual'], y=pred_df['Predicted'], mode='markers', name='Predictions'), row=1, col=1)
    
    min_val = min(pred_df['Actual'].min(), pred_df['Predicted'].min())
    max_val = max(pred_df['Actual'].max(), pred_df['Predicted'].max())
    fig.add_trace(go.Scatter(x=[min_val, max_val], y=[min_val, max_val], mode='lines', name='Perfect Prediction', line=dict(color='red', dash='dash')), row=1, col=1)
    
    # æ®‹å·®åˆ†å¸ƒ
    residuals = pred_df['Actual'] - pred_df['Predicted']
    fig.add_trace(go.Histogram(x=residuals, nbinsx=20, name='Residuals'), row=2, col=1)
    
    # æ€§èƒ½æŒ‡æ ‡
    metrics = ['MSE', 'RMSE', 'MAE']
    values = [eval_df['MSE'].iloc[0], eval_df['RMSE'].iloc[0], eval_df['MAE'].iloc[0]]
    fig.add_trace(go.Bar(x=metrics, y=values, name='Error Metrics'), row=2, col=2)
    
    fig.update_layout(height=800, showlegend=False, title_text="Model Performance Evaluation")
    return fig

# ä¸»åº”ç”¨
def main():
    st.title("ğŸ§ª åˆ†å­æ€§è´¨é¢„æµ‹ä¸æ¨¡å‹åˆ†æå¹³å°")
    st.markdown("---")
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'baseline_row' not in st.session_state:
        st.session_state.baseline_row = None
    if 'batch_results' not in st.session_state:
        st.session_state.batch_results = []
    if 'mfpgen' not in st.session_state:
        st.session_state.mfpgen = initialize_fingerprint_generator()
    if 'progress_queue' not in st.session_state:
        st.session_state.progress_queue = queue.Queue()
    if 'processing' not in st.session_state:
        st.session_state.processing = False
    if 'shap_plot_generated' not in st.session_state:
        st.session_state.shap_plot_generated = False
    if 'shap_plot_paths' not in st.session_state:
        st.session_state.shap_plot_paths = {}
    
    # åŠ è½½æ•°æ®
    df, model = load_data_and_model()
    eval_df, feat_df, pred_df = load_evaluation_data()
    
    # å¤„ç†ç‰¹å¾é‡è¦æ€§æ•°æ®ï¼ˆåˆå¹¶fpç‰¹å¾ï¼‰
    if feat_df is not None:
        processed_feat_df = process_feature_importance(feat_df)
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®")
        
        if df is not None and model is not None:
            pce_threshold = st.slider("PCEé˜ˆå€¼ (%)", min_value=0.0, max_value=float(df['JV_default_PCE'].max()), value=15.0, step=0.1)
            
            if st.button("é€‰æ‹©åŸºå‡†è¡Œ"):
                with st.spinner("æ­£åœ¨é€‰æ‹©åŸºå‡†è¡Œ..."):
                    st.session_state.baseline_row = select_baseline_row(df, pce_threshold)
        
        st.markdown("---")
        st.header("ğŸ“Š åˆ†æé€‰é¡¹")
        show_visualization = st.checkbox("æ˜¾ç¤ºé¢„æµ‹ç»“æœå¯è§†åŒ–", value=True)
        show_analysis = st.checkbox("æ˜¾ç¤ºæ¨¡å‹åˆ†æ", value=True)
        
        if show_analysis and df is not None and model is not None:
            if st.button("ç”ŸæˆSHAPåˆ†æå›¾"):
                with st.spinner("æ­£åœ¨ç”ŸæˆSHAPåˆ†æå›¾..."):
                    # å‡†å¤‡æ•°æ®ç”¨äºSHAPåˆ†æ
                    X_data = df.drop('JV_default_PCE', axis=1).values
                    feature_names = df.drop('JV_default_PCE', axis=1).columns.tolist()
                    
                    shap_plot_paths = generate_shap_plot(model, X_data, feature_names)
                    if shap_plot_paths:
                        st.session_state.shap_plot_paths = shap_plot_paths
                        st.session_state.shap_plot_generated = True
                        st.success("SHAPåˆ†æå›¾ç”ŸæˆæˆåŠŸï¼")
    
    # ä¸»ç•Œé¢
    if df is None or model is None:
        st.error("æ— æ³•åŠ è½½æ•°æ®æˆ–æ¨¡å‹ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„")
        return
    
    # æ¨¡å‹æ€§èƒ½è¯„ä¼°
    if show_analysis and eval_df is not None:
        st.subheader("ğŸ† æ¨¡å‹æ€§èƒ½è¯„ä¼°")
        col1, col2, col3, col4 = st.columns(4)
        with col1: st.metric("MSE", f"{eval_df['MSE'].iloc[0]:.4f}")
        with col2: st.metric("RMSE", f"{eval_df['RMSE'].iloc[0]:.4f}")
        with col3: st.metric("MAE", f"{eval_df['MAE'].iloc[0]:.4f}")
        with col4: st.metric("RÂ²", f"{eval_df['R2'].iloc[0]:.4f}")
        
        if pred_df is not None:
            st.plotly_chart(plot_model_performance(eval_df, pred_df), use_container_width=True)
    
    # ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆä½¿ç”¨å¤„ç†åçš„æ•°æ®ï¼‰
    if show_analysis and processed_feat_df is not None:
        st.subheader("ğŸ”‘ ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆfpç‰¹å¾å·²åˆå¹¶ï¼‰")
        top_n = st.slider("æ˜¾ç¤ºç‰¹å¾æ•°é‡", 5, 50, 20, key="feat_slider")
        st.plotly_chart(plot_feature_importance(processed_feat_df, top_n), use_container_width=True)
        
        if st.button("ä¸‹è½½å¤„ç†åçš„ç‰¹å¾é‡è¦æ€§æ•°æ®"):
            processed_feat_df.to_csv('processed_feature_importance.csv', index=False)
            st.success("å¤„ç†åçš„ç‰¹å¾é‡è¦æ€§æ•°æ®å·²ä¿å­˜")
    
    # SHAPåˆ†æå›¾æ˜¾ç¤º
    if show_analysis and st.session_state.shap_plot_generated:
        st.subheader("ğŸ“Š SHAPç‰¹å¾é‡è¦æ€§åˆ†æ")
        try:
            # åˆ›å»ºé€‰é¡¹å¡æ˜¾ç¤ºä¸åŒç±»å‹çš„å›¾è¡¨
            summary_tab, heatmap_tab, violin_tab, boxplot_tab = st.tabs([
                "æ‘˜è¦å›¾", "çƒ­åŠ›å›¾", "å°æç´å›¾", "ç®±çº¿å›¾"
            ])
            
            with summary_tab:
                st.image(st.session_state.shap_plot_paths['summary'])
                st.caption("SHAPç‰¹å¾é‡è¦æ€§æ‘˜è¦å›¾å±•ç¤ºäº†æ¯ä¸ªç‰¹å¾å¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ã€‚xè½´è¡¨ç¤ºSHAPå€¼ï¼Œçº¢è‰²è¡¨ç¤ºé«˜å½±å“ï¼Œè“è‰²è¡¨ç¤ºä½å½±å“ã€‚")
            
            with heatmap_tab:
                st.image(st.session_state.shap_plot_paths['heatmap'])
                st.caption("SHAPçƒ­åŠ›å›¾æ˜¾ç¤ºäº†ç‰¹å¾å€¼ä¸SHAPå€¼ä¹‹é—´çš„å…³ç³»ï¼Œå¸®åŠ©ç†è§£ç‰¹å¾å¦‚ä½•å½±å“æ¨¡å‹é¢„æµ‹ã€‚")
                
            with violin_tab:
                st.image(st.session_state.shap_plot_paths['violin'])
                st.caption("SHAPå°æç´å›¾å±•ç¤ºäº†æ¯ä¸ªç‰¹å¾çš„SHAPå€¼åˆ†å¸ƒæƒ…å†µï¼Œæ›´ç›´è§‚åœ°æ˜¾ç¤ºç‰¹å¾é‡è¦æ€§ã€‚")
                
            with boxplot_tab:
                st.image(st.session_state.shap_plot_paths['boxplot'])
                st.caption("SHAPç®±çº¿å›¾æ˜¾ç¤ºäº†å‰10ä¸ªæœ€é‡è¦ç‰¹å¾çš„SHAPå€¼åˆ†å¸ƒï¼Œå¯ä»¥è§‚å¯Ÿåˆ°æ•°æ®çš„å››åˆ†ä½æ•°å’Œå¼‚å¸¸å€¼ã€‚")
            
            # æä¾›æ‰€æœ‰å›¾è¡¨çš„ä¸‹è½½é€‰é¡¹
            st.subheader("ğŸ’¾ ä¸‹è½½SHAPåˆ†æå›¾")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                with open(st.session_state.shap_plot_paths['summary'], "rb") as file:
                    st.download_button(
                        label="ä¸‹è½½æ‘˜è¦å›¾",
                        data=file,
                        file_name="shap_summary_plot.png",
                        mime="image/png"
                    )
            with col2:
                with open(st.session_state.shap_plot_paths['heatmap'], "rb") as file:
                    st.download_button(
                        label="ä¸‹è½½çƒ­åŠ›å›¾",
                        data=file,
                        file_name="shap_heatmap_plot.png",
                        mime="image/png"
                    )
            with col3:
                with open(st.session_state.shap_plot_paths['violin'], "rb") as file:
                    st.download_button(
                        label="ä¸‹è½½å°æç´å›¾",
                        data=file,
                        file_name="shap_violin_plot.png",
                        mime="image/png"
                    )
            with col4:
                with open(st.session_state.shap_plot_paths['boxplot'], "rb") as file:
                    st.download_button(
                        label="ä¸‹è½½ç®±çº¿å›¾",
                        data=file,
                        file_name="shap_boxplot.png",
                        mime="image/png"
                    )
        except Exception as e:
            st.error(f"æ˜¾ç¤ºSHAPå›¾æ—¶å‡ºé”™: {e}")
    
    st.markdown("---")
    
    # é¢„æµ‹åŠŸèƒ½
    if st.session_state.baseline_row is not None:
        baseline_row = st.session_state.baseline_row
        
        col1, col2, col3 = st.columns(3)
        with col1: st.metric("åŸºå‡†è¡ŒPCE", f"{baseline_row['JV_default_PCE']:.2f}%")
        with col2: st.metric("åŸºå‡†è¡ŒID", baseline_row.name)
        with col3: st.metric("æ•°æ®ç»´åº¦", f"{df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—")
        
        # é€‰é¡¹å¡å¸ƒå±€
        tab1, tab2, tab3 = st.tabs(["å•æ¬¡é¢„æµ‹", "æ‰¹é‡é¢„æµ‹", "æ•°æ®å¯¼å‡º"])
        
        with tab1:
            st.header("ğŸ” å•æ¬¡é¢„æµ‹")
            smiles_input = st.text_area("è¾“å…¥SMILESå­—ç¬¦ä¸²", height=100, placeholder="è¾“å…¥å•ä¸ªSMILESæˆ–å¤šä¸ªSMILESï¼ˆç”¨åˆ†å·;åˆ†éš”ï¼‰")
            
            if st.button("å¼€å§‹é¢„æµ‹", key="predict_single"):
                if smiles_input.strip():
                    with st.spinner("é¢„æµ‹ä¸­..."):
                        try:
                            # æ£€æŸ¥æ˜¯å¦æœ‰é€—å·åˆ†éš”çš„å¤šä¸ªä»»åŠ¡
                            tasks = [task.strip() for task in smiles_input.split(',') if task.strip()]
                            
                            if len(tasks) > 1:
                                # å¤„ç†å¤šä¸ªä»»åŠ¡
                                results = []
                                errors = []
                                for i, task_smiles in enumerate(tasks):
                                    try:
                                        predicted_pce, modified_row = predict_with_custom_smiles(
                                            baseline_row, task_smiles, model, st.session_state.mfpgen
                                        )
                                        results.append({
                                            "task_id": i + 1,
                                            "smiles": task_smiles,
                                            "predicted_pce": float(round(predicted_pce, 2)),
                                            "baseline_pce": float(round(baseline_row['JV_default_PCE'], 2)),
                                            "change": float(round(predicted_pce - baseline_row['JV_default_PCE'], 2))
                                        })
                                    except Exception as e:
                                        error_msg = f"ä»»åŠ¡ {i+1} ('{task_smiles}') å¤„ç†å¤±è´¥: {str(e)}"
                                        errors.append(error_msg)
                                        st.error(error_msg)  # æ˜¾ç¤ºå…·ä½“é”™è¯¯ä¿¡æ¯
                                
                                # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                                if errors:
                                    for error in errors:
                                        st.warning(error)
                                
                                # æ˜¾ç¤ºç»“æœè¡¨æ ¼
                                if results:
                                    st.success(f"æˆåŠŸå¤„ç† {len(results)} ä¸ªä»»åŠ¡")
                                    results_df = pd.DataFrame(results)
                                    st.dataframe(results_df, use_container_width=True)
                                    
                                    # æ˜¾ç¤ºæœ€ä½³ç»“æœ
                                    if results:
                                        best_result = max(results, key=lambda x: x['change'])
                                        st.subheader("æœ€ä½³ç»“æœ")
                                        st.success(f"ä»»åŠ¡ID: {best_result['task_id']}, SMILES: {best_result['smiles']}")
                                        st.success(f"é¢„æµ‹PCE: **{best_result['predicted_pce']:.2f}%**")
                                        st.info(f"å˜åŒ–: **{best_result['change']:+.2f}%**")
                                else:
                                    st.error("æ‰€æœ‰ä»»åŠ¡éƒ½å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥SMILESæ ¼å¼")
                            else:
                                # å¤„ç†å•ä¸ªä»»åŠ¡
                                predicted_pce, modified_row = predict_with_custom_smiles(
                                    baseline_row, smiles_input, model, st.session_state.mfpgen
                                )
                                col1, col2 = st.columns(2)
                                with col1: st.success(f"é¢„æµ‹PCE: **{predicted_pce:.2f}%**")
                                with col2: st.info(f"å˜åŒ–: **{predicted_pce - baseline_row['JV_default_PCE']:+.2f}%**")
                        except Exception as e:
                            st.error(f"é¢„æµ‹å¤±è´¥: {e}")
                else:
                    st.warning("è¯·è¾“å…¥SMILESå­—ç¬¦ä¸²")
        
        with tab2:
            st.header("ğŸ“ æ‰¹é‡é¢„æµ‹")
            uploaded_file = st.file_uploader("ä¸Šä¼ SMILESæ–‡ä»¶", type=['txt'], help="æ¯è¡Œä¸€ä¸ªä»»åŠ¡ï¼Œå¤šä¸ªSMILESç”¨;åˆ†éš”ï¼Œä¸åŒä»»åŠ¡ç”¨æ¢è¡Œåˆ†éš”")
            
            if uploaded_file is not None and not st.session_state.processing:
                if st.button("å¼€å§‹æ‰¹é‡é¢„æµ‹", key="predict_batch"):
                    st.session_state.processing = True
                    progress_queue = st.session_state.progress_queue
                    
                    # å¯åŠ¨åå°å¤„ç†çº¿ç¨‹
                    thread = threading.Thread(
                        target=process_in_background,
                        args=(uploaded_file.getvalue(), baseline_row, model, st.session_state.mfpgen, progress_queue),
                        daemon=True
                    )
                    thread.start()
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    update_progress(progress_queue, len(uploaded_file.getvalue().decode('utf-8').split('\n')))
                    st.session_state.processing = False
            
            # æ˜¾ç¤ºæ‰¹é‡ç»“æœ
            if st.session_state.batch_results:
                results = st.session_state.batch_results
                st.success(f"æˆåŠŸå¤„ç† {len(results)} ä¸ªä»»åŠ¡")
                
                results_df = pd.DataFrame([{
                    'ä»»åŠ¡ID': r['task_id'],
                    'SMILES': r['smiles'],
                    'é¢„æµ‹PCE (%)': r['predicted_pce'],
                    'å˜åŒ– (%)': r['change']
                } for r in results])
                
                st.dataframe(results_df, use_container_width=True)
                
                # å¯è§†åŒ–
                if show_visualization:
                    st.subheader("ğŸ“ˆ é¢„æµ‹ç»“æœå¯è§†åŒ–")
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        fig_hist = px.histogram(results_df, x='é¢„æµ‹PCE (%)', nbins=20, title='é¢„æµ‹PCEåˆ†å¸ƒ')
                        st.plotly_chart(fig_hist, use_container_width=True)
                    
                    with col2:
                        changes = [r['change'] for r in results]
                        fig_changes = px.histogram(results_df, x='å˜åŒ– (%)', nbins=20, title='PCEå˜åŒ–åˆ†å¸ƒ')
                        st.plotly_chart(fig_changes, use_container_width=True)
                        
                        st.metric("å¹³å‡å˜åŒ–", f"{np.mean(changes):+.2f}%")
                        st.metric("æœ€å¤§æå‡", f"{max(changes):+.2f}%")
                        st.metric("æœ€å¤§ä¸‹é™", f"{min(changes):+.2f}%")
        
        with tab3:
            st.header("ğŸ’¾ æ•°æ®å¯¼å‡º")
            
            if st.session_state.batch_results:
                results = st.session_state.batch_results
                
                # å¯¼å‡ºJSON
                json_data = export_to_json(results)
                st.download_button("ä¸‹è½½é¢„æµ‹ç»“æœ (JSON)", data=json_data, file_name="predictions.json", mime="application/json")
                
                # å¯¼å‡ºCSV
                csv_data = pd.DataFrame([{
                    'task_id': r['task_id'],
                    'smiles': r['smiles'],
                    'predicted_pce': r['predicted_pce'],
                    'baseline_pce': r['baseline_pce'],
                    'change': r['change']
                } for r in results]).to_csv(index=False)
                
                st.download_button("ä¸‹è½½é¢„æµ‹ç»“æœ (CSV)", data=csv_data, file_name="predictions.csv", mime="text/csv")
            else:
                st.info("æš‚æ— æ‰¹é‡é¢„æµ‹ç»“æœå¯ä¾›å¯¼å‡º")
            
            # å¯¼å‡ºåŸºå‡†è¡Œæ•°æ®
            if st.session_state.baseline_row is not None:
                baseline_df = pd.DataFrame([st.session_state.baseline_row])
                baseline_csv = baseline_df.to_csv(index=False)
                st.download_button("ä¸‹è½½åŸºå‡†è¡Œæ•°æ®", data=baseline_csv, file_name="baseline.csv", mime="text/csv")
    
    else:
        st.info("è¯·åœ¨ä¾§è¾¹æ é€‰æ‹©åŸºå‡†è¡Œä»¥å¼€å§‹é¢„æµ‹")

if __name__ == "__main__":
    main()